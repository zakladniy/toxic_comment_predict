{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:46:50.637305Z",
     "start_time": "2022-02-26T16:46:48.231720Z"
    },
    "id": "RunCY9jdWLyR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transformers import BertTokenizer\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    BertForSequenceClassification,\n",
    "    AutoConfig,\n",
    ")\n",
    "from torch.utils.data import (\n",
    "    TensorDataset,\n",
    "    DataLoader,\n",
    "    RandomSampler,\n",
    "    SequentialSampler,\n",
    ")\n",
    "from transformers import BertModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:46:51.467875Z",
     "start_time": "2022-02-26T16:46:51.457221Z"
    },
    "id": "V3d1HQNmUtp4"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWQvc23jS1Ck"
   },
   "source": [
    "# Check type of GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:46:52.056835Z",
     "start_time": "2022-02-26T16:46:52.014324Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2GJ_KMM_RLrd",
    "outputId": "7124d34b-ca9e-4f0a-f4d0-82c3062e1880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWxl-TqYUQ5d"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdchA59DVDwB"
   },
   "source": [
    "## Load data from local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:46:54.344082Z",
     "start_time": "2022-02-26T16:46:54.229656Z"
    },
    "id": "5gXY8Csvx3rf"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    '../data/external data/russian_comments_from_2ch_pikabu.csv').drop(\n",
    "    'translated', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeM2t9a7VIe6"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:46:54.901796Z",
     "start_time": "2022-02-26T16:46:54.878842Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPXBo3H2VHnd",
    "outputId": "decffffb-bcda-4c4e-a2c5-3af4583b9537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14412 entries, 0 to 14411\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   comment  14412 non-null  object \n",
      " 1   toxic    14412 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 225.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:46:55.202922Z",
     "start_time": "2022-02-26T16:46:55.160374Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cOiaDZMMVHqU",
    "outputId": "0a0e044e-682e-40b2-e7e7-e24a7ac23e73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data) - len(data.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:46:55.474121Z",
     "start_time": "2022-02-26T16:46:55.467137Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "SEQDM6PVVa8f",
    "outputId": "afe78ea3-2690-4be6-ce3e-145c97d19056"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скрипалей отравила Россия? Анализировать и думать пытаешься? Ватник что ли?)\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                     comment  toxic\n",
       "0                                                                                                                                                       Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1                                                                 Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\\n    1.0\n",
       "2                                                                                                                                                                  Собаке - собачья смерть\\n    1.0\n",
       "3  Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?\\n    1.0\n",
       "4                                                                  тебя не убедил 6-страничный пдф в том, что Скрипалей отравила Россия? Анализировать и думать пытаешься? Ватник что ли?)\\n    1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:46:56.234360Z",
     "start_time": "2022-02-26T16:46:56.126751Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "zZFAGjaWVHs7",
    "outputId": "bbfb64c6-fb92-4d58-85e3-7277ca2a69de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['toxic'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:46:57.341429Z",
     "start_time": "2022-02-26T16:46:57.286633Z"
    },
    "id": "YM-3UKAcVHvs"
   },
   "outputs": [],
   "source": [
    "data_len = data['comment'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:46:57.694772Z",
     "start_time": "2022-02-26T16:46:57.591017Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "F3Gs1vGbWEyz",
    "outputId": "6bcd4855-a5e8-4e5e-8b86-d71fc3e30876"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data_len, bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:46:58.137876Z",
     "start_time": "2022-02-26T16:46:58.130602Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rSVTASXnWToy",
    "outputId": "f2f87bb7-cd42-4239-e89a-d0aeab47e245"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1078, 1, 27.94601720788232)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_len_np = np.array(data_len)\n",
    "\n",
    "np.max(data_len_np), np.min(data_len_np), np.mean(data_len_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XITRwtNFVuyx"
   },
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:46:59.741119Z",
     "start_time": "2022-02-26T16:46:59.726357Z"
    },
    "id": "1sk_qxdWVHyZ"
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(text: str) -> str:\n",
    "    \"\"\"Drop thrash symbols from text\n",
    "\n",
    "    @param text: raw text\n",
    "    @return: clean text\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"<[^>]*>\", \" \", text)\n",
    "    text = re.sub(r\"^\\[id\\d*|.*\\],*\\s*\", \"\", text)\n",
    "    text = re.sub(r\"(&quot;)|(&lt;)|(&gt;)|(&amp;)|(&apos;)\", \" \", text)\n",
    "    text = re.sub(r\"https?://(www\\.)?[-a-zA-Z0-9@:%._+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_+.~#?&/=]*)\",\" \", text)\n",
    "    text = re.sub(r\"\\[[^\\[\\]]+\\|([^\\[\\]]+)\\]\", r\"\\1\", text)\n",
    "    text = re.sub(r\"(&#\\d+;)\", \" \", text)\n",
    "    text = re.sub(r\"[(_#*=^/`@«»©…“•—<>\\[\\]\\\"'+%|&]\", \" \", text)\n",
    "    text = re.sub(r\"[\\;:)(_#*=^/`@«»©…“•—<>\\[\\]\\\"'+%|&]\", \" \", text)\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    text = text.replace(\"--\", \" \")\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(\"\\s\\s+\", \" \", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:00.382867Z",
     "start_time": "2022-02-26T16:47:00.366380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Верблюдов-то за что? Дебилы, бл...'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessing('Верблюдов-то за что? Дебилы, бл...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:02.519790Z",
     "start_time": "2022-02-26T16:47:00.630878Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJNJ4lVHzPyF",
    "outputId": "dcc321e4-b6f8-4f77-9928-1fa3b1f4b4a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14412/14412 [00:01<00:00, 7654.20it/s] \n"
     ]
    }
   ],
   "source": [
    "data['comment_clean'] = data['comment'].progress_apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:02.993689Z",
     "start_time": "2022-02-26T16:47:02.983338Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "nysF9cPJzP1W",
    "outputId": "5fa31242-0c37-4f96-84de-b5f1dbcdceb3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "      <th>comment_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Собаке - собачья смерть</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скрипалей отравила Россия? Анализировать и думать пытаешься? Ватник что ли?)\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скрипалей отравила Россия? Анализировать и думать пытаешься? Ватник что ли?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                     comment  toxic                                                                                                                                                                            comment_clean\n",
       "0                                                                                                                                                       Верблюдов-то за что? Дебилы, бл...\\n    1.0                                                                                                                                                       Верблюдов-то за что? Дебилы, бл...\n",
       "1                                                                 Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\\n    1.0                                                                 Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\n",
       "2                                                                                                                                                                  Собаке - собачья смерть\\n    1.0                                                                                                                                                                  Собаке - собачья смерть\n",
       "3  Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?\\n    1.0  Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?\n",
       "4                                                                  тебя не убедил 6-страничный пдф в том, что Скрипалей отравила Россия? Анализировать и думать пытаешься? Ватник что ли?)\\n    1.0                                                                   тебя не убедил 6-страничный пдф в том, что Скрипалей отравила Россия? Анализировать и думать пытаешься? Ватник что ли?"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2UF1RVIbY9_"
   },
   "source": [
    "## Train, valid, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:03.784213Z",
     "start_time": "2022-02-26T16:47:03.773355Z"
    },
    "id": "FFQ6jkzhY0-F"
   },
   "outputs": [],
   "source": [
    "data['toxic'] = data['toxic'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:04.045042Z",
     "start_time": "2022-02-26T16:47:04.021129Z"
    },
    "id": "g-pj5RmFzP4O"
   },
   "outputs": [],
   "source": [
    "X = list(data['comment_clean'])\n",
    "y = list(data['toxic'])\n",
    "\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:04.535815Z",
     "start_time": "2022-02-26T16:47:04.522746Z"
    },
    "id": "i8SlMJhbY0Kr"
   },
   "outputs": [],
   "source": [
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_tmp,\n",
    "    y_tmp,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=y_tmp,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:05.143117Z",
     "start_time": "2022-02-26T16:47:05.134836Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lwWKyg9ZzP65",
    "outputId": "e681f10c-3ee3-4ee7-f93f-212ec9da1974"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11529, 1441, 1442)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_valid), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9die7W3b_1U"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJSwF7_JcqGt"
   },
   "source": [
    "## Load BERT tokenizer, config and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:13.948004Z",
     "start_time": "2022-02-26T16:47:10.375566Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PSJQ77Fdb9wh",
    "outputId": "d82e1b75-b17c-4546-9927-9631bc1dada5"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "config = AutoConfig.from_pretrained(\"cointegrated/rubert-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:16.095584Z",
     "start_time": "2022-02-26T16:47:14.966421Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YMa8jqFfb9z6",
    "outputId": "0d3bf0f1-acf1-4d7d-99c2-492b123bd0f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"cointegrated/rubert-tiny\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yoy9JRA7c2Yh"
   },
   "source": [
    "## Check len after tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:39.195696Z",
     "start_time": "2022-02-26T16:47:37.168615Z"
    },
    "id": "b-SdNQjMc-gn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "x_train_tok = list(map(lambda x: tokenizer.tokenize(x), X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:40.933956Z",
     "start_time": "2022-02-26T16:47:40.926741Z"
    },
    "id": "RBmJWPZweD3O"
   },
   "outputs": [],
   "source": [
    "x_train_len_tok = list(map(len, x_train_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:41.463552Z",
     "start_time": "2022-02-26T16:47:41.455452Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ARVPH5zkc-nV",
    "outputId": "f1f82abc-d3d0-47f8-ae63-7d330c0d7da5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2139, 3, 58.77725735102784)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_len_tok_np = np.array(x_train_len_tok)\n",
    "\n",
    "(\n",
    "    np.max(x_train_len_tok_np),\n",
    "    np.min(x_train_len_tok_np),\n",
    "    np.mean(x_train_len_tok_np),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:43.187308Z",
     "start_time": "2022-02-26T16:47:43.174750Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.784794"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(param.numel() for param in model.parameters()) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:44.772619Z",
     "start_time": "2022-02-26T16:47:44.765590Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-GTL7EdfqEc"
   },
   "source": [
    "## Prepare data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:46.947662Z",
     "start_time": "2022-02-26T16:47:45.917427Z"
    },
    "id": "bTL2z_LI0Wgv"
   },
   "outputs": [],
   "source": [
    "MAX_LENGHT = 512\n",
    "\n",
    "X_train_tok = tokenizer(\n",
    "    X_train, padding=True, truncation=True, max_length=MAX_LENGHT)\n",
    "X_val_tok = tokenizer(\n",
    "    X_valid, padding=True, truncation=True, max_length=MAX_LENGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:49.608892Z",
     "start_time": "2022-02-26T16:47:49.605915Z"
    },
    "id": "aSyLAZZl1ILN"
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):    \n",
    "    def __init__(self, encodings, labels=None):          \n",
    "        self.encodings = encodings        \n",
    "        self.labels = labels   \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:52.240104Z",
     "start_time": "2022-02-26T16:47:52.238253Z"
    },
    "id": "B-olFsK5f2ih"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train_tok, y_train)\n",
    "validation_dataset = Dataset(X_val_tok, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVlmcsJwiDGQ"
   },
   "source": [
    "## Train and validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:47:54.835932Z",
     "start_time": "2022-02-26T16:47:54.833120Z"
    },
    "id": "chgQyLOx1PTF"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, pred).ravel()\n",
    "    return {\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1\": f1,\n",
    "        'TP': tp,\n",
    "        'TN': tn,\n",
    "        'FP': fp,\n",
    "        'FN': fn,\n",
    "        } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:48:00.493247Z",
     "start_time": "2022-02-26T16:47:57.536166Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZJRU8d5S1S01",
    "outputId": "c78d4585-1da4-4275-ad21-bd9765c092ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (ruamel.yaml 0.17.16 (/home/anton/.local/lib/python3.8/site-packages), Requirement.parse('ruamel.yaml<0.17.5,>=0.15.35')).\n"
     ]
    }
   ],
   "source": [
    "# Define Trainer\n",
    "N_EPOCHS = 3\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=N_EPOCHS,\n",
    "    seed=42,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:51:43.106495Z",
     "start_time": "2022-02-26T16:48:03.231783Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "SC6JEiR81Xhd",
    "outputId": "b6d12d79-718d-47d4-c91c-94a76489aad6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1083' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1083 03:38 < 00:18, 4.56 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Tp</th>\n",
       "      <th>Tn</th>\n",
       "      <th>Fp</th>\n",
       "      <th>Fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.353462</td>\n",
       "      <td>0.795964</td>\n",
       "      <td>0.736515</td>\n",
       "      <td>0.765086</td>\n",
       "      <td>355</td>\n",
       "      <td>868</td>\n",
       "      <td>91</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.317908</td>\n",
       "      <td>0.777567</td>\n",
       "      <td>0.848548</td>\n",
       "      <td>0.811508</td>\n",
       "      <td>409</td>\n",
       "      <td>842</td>\n",
       "      <td>117</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.314806</td>\n",
       "      <td>0.824053</td>\n",
       "      <td>0.767635</td>\n",
       "      <td>0.794844</td>\n",
       "      <td>370</td>\n",
       "      <td>880</td>\n",
       "      <td>79</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.303147</td>\n",
       "      <td>0.796477</td>\n",
       "      <td>0.844398</td>\n",
       "      <td>0.819738</td>\n",
       "      <td>407</td>\n",
       "      <td>855</td>\n",
       "      <td>104</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.330200</td>\n",
       "      <td>0.296991</td>\n",
       "      <td>0.822547</td>\n",
       "      <td>0.817427</td>\n",
       "      <td>0.819979</td>\n",
       "      <td>394</td>\n",
       "      <td>874</td>\n",
       "      <td>85</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.330200</td>\n",
       "      <td>0.292373</td>\n",
       "      <td>0.817814</td>\n",
       "      <td>0.838174</td>\n",
       "      <td>0.827869</td>\n",
       "      <td>404</td>\n",
       "      <td>869</td>\n",
       "      <td>90</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.330200</td>\n",
       "      <td>0.290638</td>\n",
       "      <td>0.828157</td>\n",
       "      <td>0.829876</td>\n",
       "      <td>0.829016</td>\n",
       "      <td>400</td>\n",
       "      <td>876</td>\n",
       "      <td>83</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.330200</td>\n",
       "      <td>0.310687</td>\n",
       "      <td>0.777164</td>\n",
       "      <td>0.875519</td>\n",
       "      <td>0.823415</td>\n",
       "      <td>422</td>\n",
       "      <td>838</td>\n",
       "      <td>121</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.330200</td>\n",
       "      <td>0.300009</td>\n",
       "      <td>0.813121</td>\n",
       "      <td>0.848548</td>\n",
       "      <td>0.830457</td>\n",
       "      <td>409</td>\n",
       "      <td>865</td>\n",
       "      <td>94</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.298851</td>\n",
       "      <td>0.816367</td>\n",
       "      <td>0.848548</td>\n",
       "      <td>0.832146</td>\n",
       "      <td>409</td>\n",
       "      <td>867</td>\n",
       "      <td>92</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric eval_loss:\n",
      "0.3534621298313141\n",
      "Attempted to log scalar metric eval_Precision:\n",
      "0.7959641255605381\n",
      "Attempted to log scalar metric eval_Recall:\n",
      "0.7365145228215768\n",
      "Attempted to log scalar metric eval_F1:\n",
      "0.7650862068965517\n",
      "Attempted to log scalar metric eval_TP:\n",
      "355\n",
      "Attempted to log scalar metric eval_TN:\n",
      "868\n",
      "Attempted to log scalar metric eval_FP:\n",
      "91\n",
      "Attempted to log scalar metric eval_FN:\n",
      "127\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "2.815\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "511.893\n",
      "Attempted to log scalar metric epoch:\n",
      "0.28\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.31790757179260254\n",
      "Attempted to log scalar metric eval_Precision:\n",
      "0.7775665399239544\n",
      "Attempted to log scalar metric eval_Recall:\n",
      "0.8485477178423236\n",
      "Attempted to log scalar metric eval_F1:\n",
      "0.8115079365079365\n",
      "Attempted to log scalar metric eval_TP:\n",
      "409\n",
      "Attempted to log scalar metric eval_TN:\n",
      "842\n",
      "Attempted to log scalar metric eval_FP:\n",
      "117\n",
      "Attempted to log scalar metric eval_FN:\n",
      "73\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "2.8314\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "508.937\n",
      "Attempted to log scalar metric epoch:\n",
      "0.55\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.3148055970668793\n",
      "Attempted to log scalar metric eval_Precision:\n",
      "0.8240534521158129\n",
      "Attempted to log scalar metric eval_Recall:\n",
      "0.7676348547717843\n",
      "Attempted to log scalar metric eval_F1:\n",
      "0.7948442534908701\n",
      "Attempted to log scalar metric eval_TP:\n",
      "370\n",
      "Attempted to log scalar metric eval_TN:\n",
      "880\n",
      "Attempted to log scalar metric eval_FP:\n",
      "79\n",
      "Attempted to log scalar metric eval_FN:\n",
      "112\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "2.9881\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "482.242\n",
      "Attempted to log scalar metric epoch:\n",
      "0.83\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.3031473755836487\n",
      "Attempted to log scalar metric eval_Precision:\n",
      "0.7964774951076321\n",
      "Attempted to log scalar metric eval_Recall:\n",
      "0.8443983402489627\n",
      "Attempted to log scalar metric eval_F1:\n",
      "0.8197381671701913\n",
      "Attempted to log scalar metric eval_TP:\n",
      "407\n",
      "Attempted to log scalar metric eval_TN:\n",
      "855\n",
      "Attempted to log scalar metric eval_FP:\n",
      "104\n",
      "Attempted to log scalar metric eval_FN:\n",
      "75\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "2.9789\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "483.738\n",
      "Attempted to log scalar metric epoch:\n",
      "1.11\n",
      "Attempted to log scalar metric loss:\n",
      "0.3302\n",
      "Attempted to log scalar metric learning_rate:\n",
      "2.6915974145891044e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "1.39\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.2969912588596344\n",
      "Attempted to log scalar metric eval_Precision:\n",
      "0.8225469728601252\n",
      "Attempted to log scalar metric eval_Recall:\n",
      "0.8174273858921162\n",
      "Attempted to log scalar metric eval_F1:\n",
      "0.8199791883454736\n",
      "Attempted to log scalar metric eval_TP:\n",
      "394\n",
      "Attempted to log scalar metric eval_TN:\n",
      "874\n",
      "Attempted to log scalar metric eval_FP:\n",
      "85\n",
      "Attempted to log scalar metric eval_FN:\n",
      "88\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "3.0686\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "469.601\n",
      "Attempted to log scalar metric epoch:\n",
      "1.39\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.2923733592033386\n",
      "Attempted to log scalar metric eval_Precision:\n",
      "0.8178137651821862\n",
      "Attempted to log scalar metric eval_Recall:\n",
      "0.8381742738589212\n",
      "Attempted to log scalar metric eval_F1:\n",
      "0.8278688524590163\n",
      "Attempted to log scalar metric eval_TP:\n",
      "404\n",
      "Attempted to log scalar metric eval_TN:\n",
      "869\n",
      "Attempted to log scalar metric eval_FP:\n",
      "90\n",
      "Attempted to log scalar metric eval_FN:\n",
      "78\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "2.8422\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "507.004\n",
      "Attempted to log scalar metric epoch:\n",
      "1.66\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.29063817858695984\n",
      "Attempted to log scalar metric eval_Precision:\n",
      "0.8281573498964804\n",
      "Attempted to log scalar metric eval_Recall:\n",
      "0.8298755186721992\n",
      "Attempted to log scalar metric eval_F1:\n",
      "0.8290155440414508\n",
      "Attempted to log scalar metric eval_TP:\n",
      "400\n",
      "Attempted to log scalar metric eval_TN:\n",
      "876\n",
      "Attempted to log scalar metric eval_FP:\n",
      "83\n",
      "Attempted to log scalar metric eval_FN:\n",
      "82\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "3.0638\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "470.325\n",
      "Attempted to log scalar metric epoch:\n",
      "1.94\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.3106873035430908\n",
      "Attempted to log scalar metric eval_Precision:\n",
      "0.7771639042357275\n",
      "Attempted to log scalar metric eval_Recall:\n",
      "0.8755186721991701\n",
      "Attempted to log scalar metric eval_F1:\n",
      "0.8234146341463414\n",
      "Attempted to log scalar metric eval_TP:\n",
      "422\n",
      "Attempted to log scalar metric eval_TN:\n",
      "838\n",
      "Attempted to log scalar metric eval_FP:\n",
      "121\n",
      "Attempted to log scalar metric eval_FN:\n",
      "60\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "2.9144\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "494.445\n",
      "Attempted to log scalar metric epoch:\n",
      "2.22\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.30000877380371094\n",
      "Attempted to log scalar metric eval_Precision:\n",
      "0.8131212723658051\n",
      "Attempted to log scalar metric eval_Recall:\n",
      "0.8485477178423236\n",
      "Attempted to log scalar metric eval_F1:\n",
      "0.8304568527918782\n",
      "Attempted to log scalar metric eval_TP:\n",
      "409\n",
      "Attempted to log scalar metric eval_TN:\n",
      "865\n",
      "Attempted to log scalar metric eval_FP:\n",
      "94\n",
      "Attempted to log scalar metric eval_FN:\n",
      "73\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "2.906\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "495.864\n",
      "Attempted to log scalar metric epoch:\n",
      "2.49\n",
      "Attempted to log scalar metric loss:\n",
      "0.2145\n",
      "Attempted to log scalar metric learning_rate:\n",
      "3.831948291782087e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "2.77\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.2988510727882385\n",
      "Attempted to log scalar metric eval_Precision:\n",
      "0.8163672654690619\n",
      "Attempted to log scalar metric eval_Recall:\n",
      "0.8485477178423236\n",
      "Attempted to log scalar metric eval_F1:\n",
      "0.8321464903357071\n",
      "Attempted to log scalar metric eval_TP:\n",
      "409\n",
      "Attempted to log scalar metric eval_TN:\n",
      "867\n",
      "Attempted to log scalar metric eval_FP:\n",
      "92\n",
      "Attempted to log scalar metric eval_FN:\n",
      "73\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "2.9446\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "489.377\n",
      "Attempted to log scalar metric epoch:\n",
      "2.77\n",
      "Attempted to log scalar metric train_runtime:\n",
      "219.3165\n",
      "Attempted to log scalar metric train_samples_per_second:\n",
      "4.938\n",
      "Attempted to log scalar metric total_flos:\n",
      "0\n",
      "Attempted to log scalar metric epoch:\n",
      "2.77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.27233750915527344, metrics={'train_runtime': 219.3165, 'train_samples_per_second': 4.938, 'total_flos': 0, 'epoch': 2.77, 'init_mem_cpu_alloc_delta': 2168438784, 'init_mem_gpu_alloc_delta': 48010752, 'init_mem_cpu_peaked_delta': 27078656, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 52166656, 'train_mem_gpu_alloc_delta': 141856768, 'train_mem_cpu_peaked_delta': 36823040, 'train_mem_gpu_peaked_delta': 5278008320})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIK1Wk02jdJ0"
   },
   "source": [
    "## Save tokenizer, config and model to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:52:25.383989Z",
     "start_time": "2022-02-26T16:52:25.327431Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SoNndX978-e7",
    "outputId": "9ce135d6-9efb-4f15-b986-9f0f5fd3d8a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving tokenizer to ../model/tokenizer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../model/tokenizer/tokenizer_config.json',\n",
       " '../model/tokenizer/special_tokens_map.json',\n",
       " '../model/tokenizer/vocab.txt',\n",
       " '../model/tokenizer/added_tokens.json',\n",
       " '../model/tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save BERT tokenizer\n",
    "\n",
    "output_dir = '../model/tokenizer'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving tokenizer to %s\" % output_dir)\n",
    "\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:52:28.097756Z",
     "start_time": "2022-02-26T16:52:28.094764Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYCHheNW8-hx",
    "outputId": "dc9f36b6-51a5-44c2-81c3-5eed6c624b25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving tokenizer to ../model/tokenizer\n"
     ]
    }
   ],
   "source": [
    "# Save config\n",
    "\n",
    "output_dir = '../model/tokenizer'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving tokenizer to %s\" % output_dir)\n",
    "\n",
    "config.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:52:30.912529Z",
     "start_time": "2022-02-26T16:52:30.799756Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6RXfHLONj7T_",
    "outputId": "6ea48732-4000-4d0d-9b69-87e6493c33e1"
   },
   "outputs": [],
   "source": [
    "# Save BERT model\n",
    "\n",
    "trainer.save_model('../model/bert_toxic_predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Od8lKFhVkSF6"
   },
   "source": [
    "## Validation model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:52:33.621830Z",
     "start_time": "2022-02-26T16:52:33.619306Z"
    },
    "id": "dUWg-YJRj7ny"
   },
   "outputs": [],
   "source": [
    "def get_prediction(text):\n",
    "    inputs = tokenizer(\n",
    "        [text],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGHT,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to('cuda')\n",
    "    outputs = model(**inputs)\n",
    "    probs = outputs[0].softmax(1).to('cpu').detach().numpy()\n",
    "    proba = probs[0]\n",
    "    return 1 if proba[1] > 0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:52:40.082844Z",
     "start_time": "2022-02-26T16:52:36.284144Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_YT8NSH_k9yF",
    "outputId": "a829c9c4-5615-4e42-8f84-b9b0a8728105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n"
     ]
    }
   ],
   "source": [
    "test_preds = []\n",
    "\n",
    "for i, item in enumerate(X_test):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    test_preds.append(get_prediction(item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:52:42.812290Z",
     "start_time": "2022-02-26T16:52:42.803682Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jNuIm-Upk96v",
    "outputId": "8328e599-2b04-4e44-a4da-58dc9af9dbb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score metric on test data: 0.8190279214064117\n",
      "Precision metric on test data: 0.8181818181818182\n",
      "Recall metric on test data: 0.8198757763975155\n"
     ]
    }
   ],
   "source": [
    "print(f\"F1-score metric on test data: {f1_score(y_test, test_preds)}\")\n",
    "print(f\"Precision metric on test data: {precision_score(y_test, test_preds)}\")\n",
    "print(f\"Recall metric on test data: {recall_score(y_test, test_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:52:45.923016Z",
     "start_time": "2022-02-26T16:52:45.902919Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hMu5kmFrk9_s",
    "outputId": "4d5b9da9-e88a-46b2-86ca-d9ee7462a369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors:\n",
      "FP: 88\n",
      "FN: 87\n",
      "TN: 871\n",
      "TP: 396\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, test_preds).ravel()\n",
    "\n",
    "print('Errors:')\n",
    "print(f'FP: {fp}')\n",
    "print(f'FN: {fn}')\n",
    "print(f'TN: {tn}')\n",
    "print(f'TP: {tp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eK7_8e5UpnHE"
   },
   "source": [
    "# Full inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:52:48.708752Z",
     "start_time": "2022-02-26T16:52:48.695617Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fnD1J4Yq8-kd",
    "outputId": "043d1794-1a7d-4a9a-b52a-f3a2558a4c52"
   },
   "outputs": [],
   "source": [
    "tokenizer_from_file = AutoTokenizer.from_pretrained('../model/tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:52:51.504376Z",
     "start_time": "2022-02-26T16:52:51.414983Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GMnZCtCk879b",
    "outputId": "e43d3819-6bb1-4647-ab9c-7dceee99c1bf"
   },
   "outputs": [],
   "source": [
    "model_from_file = BertForSequenceClassification.from_pretrained(\n",
    "    '../model/bert_toxic_predict', num_labels=2).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:52:54.206380Z",
     "start_time": "2022-02-26T16:52:54.203585Z"
    },
    "id": "gU5S5jR11bJd"
   },
   "outputs": [],
   "source": [
    "def get_prediction(text, tokenizer, model, max_length=128):\n",
    "    text = text_preprocessing(text)\n",
    "    inputs = tokenizer(\n",
    "        [text],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to('cpu')\n",
    "    outputs = model(**inputs)\n",
    "    probs = outputs[0].softmax(1).to('cpu').detach().numpy()\n",
    "    proba = probs[0]\n",
    "    return 'Toxic' if proba[1] > 0.5 else 'Non toxic', float(proba[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:52:56.925498Z",
     "start_time": "2022-02-26T16:52:56.872303Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k7DDl_aE-Mo8",
    "outputId": "ee01165d-110c-498a-bee4-95fd9b8f6c85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Toxic', 0.9560098648071289)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(\n",
    "    text='Ну ты и баклан',\n",
    "    tokenizer=tokenizer_from_file,\n",
    "    model=model_from_file,\n",
    "    max_length=MAX_LENGHT,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Pcl8-sE-Y7y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5z7r6TFb-WjV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled45.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
